{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'swedish-bert-models'...\n",
      "Python was not found but can be installed from the Microsoft Store: https://go.microsoft.com/fwlink?linkID=2082640\n",
      "'source' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Using cached pip-20.2.3-py2.py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.1\n",
      "    Uninstalling pip-20.1:\n",
      "      Successfully uninstalled pip-20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Åtkomst nekad: 'C:\\\\Users\\\\kalle\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-cp_5kc9s\\\\pip.exe'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-3.3.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2020.9.27-cp37-cp37m-win_amd64.whl (268 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\kalle\\venvs\\jt\\lib\\site-packages (from transformers) (1.18.3)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.50.0-py2.py3-none-any.whl (70 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\kalle\\venvs\\jt\\lib\\site-packages (from transformers) (2.23.0)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-win_amd64.whl (1.9 MB)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: six in c:\\users\\kalle\\venvs\\jt\\lib\\site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Collecting click\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\kalle\\venvs\\jt\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kalle\\venvs\\jt\\lib\\site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kalle\\venvs\\jt\\lib\\site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kalle\\venvs\\jt\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kalle\\venvs\\jt\\lib\\site-packages (from requests->transformers) (1.25.9)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893262 sha256=f43ad9ac3c2f83787ead0e98e2ce5408d0ba818999346b6dd6e85094d5c51080\n",
      "  Stored in directory: c:\\users\\kalle\\appdata\\local\\pip\\cache\\wheels\\69\\09\\d1\\bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, click, joblib, tqdm, sacremoses, packaging, tokenizers, sentencepiece, filelock, transformers\n",
      "Successfully installed click-7.1.2 filelock-3.0.12 joblib-0.16.0 packaging-20.4 regex-2020.9.27 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 tqdm-4.50.0 transformers-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Kungbib/swedish-bert-models\n",
    "!cd swedish-bert-models\n",
    "#!python3 -m venv venv\n",
    "#!source venv/bin/activate\n",
    "!pip install --upgrade pip\n",
    "#!pip install -r requirements.txt\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel,AutoTokenizer,TFAutoModel\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
    "model = AutoModel.from_pretrained('KB/bert-base-swedish-cased')\n",
    "\n",
    "# Using TF models\n",
    "model = TFAutoModel.from_pretrained('KB/bert-base-swedish-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6c8a12fe8b7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTFBertForTokenClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ner'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'KB/bert-base-swedish-cased-ner'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'KB/bert-base-swedish-cased-ner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Kalle och Pelle startar firman Kalle och Pelle.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline,TFBertForTokenClassification\n",
    "\n",
    "nlp = pipeline('ner', model='KB/bert-base-swedish-cased-ner', tokenizer='KB/bert-base-swedish-cased-ner')\n",
    "\n",
    "p=nlp('Kalle och Pelle startar firman Kalle och Pelle.')\n",
    "print(p)\n",
    "\n",
    "# Specifically using Tensorflow\n",
    "\n",
    "tf = TFBertForTokenClassification.from_pretrained('KB/bert-base-swedish-cased-ner')\n",
    "nlp = pipeline('ner', model=tf, tokenizer='KB/bert-base-swedish-cased-ner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Engelbert tar sin Rolls-Royce till Tele2 Arena för att titta på Djurgården IF ' +\\\n",
    "       'som spelar fotboll i VM klockan två på kvällen.'\n",
    "\n",
    "nlp = pipeline('ner', model='KB/bert-base-swedish-cased-ner', tokenizer='KB/bert-base-swedish-cased-ner', ignore_labels=[])\n",
    "l = []\n",
    "t = nlp(text)\n",
    "in_word=False\n",
    "\n",
    "for i,token in enumerate(t):\n",
    "    if token['entity'] == 'O':\n",
    "        in_word = False\n",
    "        continue\n",
    "\n",
    "    if token['word'].startswith('##'):\n",
    "        # deal with (one level of) orphaned ##-tokens\n",
    "        if not in_word:\n",
    "            l += [ t[i-1] ]\n",
    "            l[-1]['entity'] = token['entity']\n",
    "        \n",
    "        l[-1]['word'] += token['word'][2:]\n",
    "    else:\n",
    "        l += [ token ]\n",
    "\n",
    "    in_word = True\n",
    "\n",
    "print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
