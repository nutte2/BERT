{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Kungbib/swedish-bert-models\n",
    "!cd swedish-bert-models\n",
    "!python3 -m venv venv\n",
    "!source venv/bin/activate\n",
    "!pip install --upgrade pip\n",
    "!pip install -r requirements.txt",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel,AutoTokenizer,TFAutoModel\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
    "model = AutoModel.from_pretrained('KB/bert-base-swedish-cased')\n",
    "\n",
    "# Using TF models\n",
    "model = TFAutoModel.from_pretrained('KB/bert-base-swedish-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline,TFBertForTokenClassification\n",
    "\n",
    "nlp = pipeline('ner', model='KB/bert-base-swedish-cased-ner', tokenizer='KB/bert-base-swedish-cased-ner')\n",
    "\n",
    "p=nlp('Kalle och Pelle startar firman Kalle och Pelle.')\n",
    "print(p)\n",
    "\n",
    "# Specifically using Tensorflow\n",
    "\n",
    "tf = TFBertForTokenClassification.from_pretrained('KB/bert-base-swedish-cased-ner')\n",
    "nlp = pipeline('ner', model=tf, tokenizer='KB/bert-base-swedish-cased-ner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Engelbert tar sin Rolls-Royce till Tele2 Arena för att titta på Djurgården IF ' +\\\n",
    "       'som spelar fotboll i VM klockan två på kvällen.'\n",
    "\n",
    "nlp = pipeline('ner', model='KB/bert-base-swedish-cased-ner', tokenizer='KB/bert-base-swedish-cased-ner', ignore_labels=[])\n",
    "l = []\n",
    "t = nlp(text)\n",
    "in_word=False\n",
    "\n",
    "for i,token in enumerate(t):\n",
    "    if token['entity'] == 'O':\n",
    "        in_word = False\n",
    "        continue\n",
    "\n",
    "    if token['word'].startswith('##'):\n",
    "        # deal with (one level of) orphaned ##-tokens\n",
    "        if not in_word:\n",
    "            l += [ t[i-1] ]\n",
    "            l[-1]['entity'] = token['entity']\n",
    "        \n",
    "        l[-1]['word'] += token['word'][2:]\n",
    "    else:\n",
    "        l += [ token ]\n",
    "\n",
    "    in_word = True\n",
    "\n",
    "print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
